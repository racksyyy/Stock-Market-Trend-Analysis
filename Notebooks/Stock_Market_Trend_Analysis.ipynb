{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d3d92463",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in d:\\vscode\\projects\\stock-market-trend-analysis\\.venv\\lib\\site-packages (2.4.1)\n",
      "Requirement already satisfied: yfinance in d:\\vscode\\projects\\stock-market-trend-analysis\\.venv\\lib\\site-packages (1.0)\n",
      "Requirement already satisfied: pandas in d:\\vscode\\projects\\stock-market-trend-analysis\\.venv\\lib\\site-packages (2.3.3)\n",
      "Requirement already satisfied: matplotlib in d:\\vscode\\projects\\stock-market-trend-analysis\\.venv\\lib\\site-packages (3.10.8)\n",
      "Requirement already satisfied: xgboost in d:\\vscode\\projects\\stock-market-trend-analysis\\.venv\\lib\\site-packages (3.1.3)\n",
      "Requirement already satisfied: nltk in d:\\vscode\\projects\\stock-market-trend-analysis\\.venv\\lib\\site-packages (3.9.2)\n",
      "Requirement already satisfied: scipy in d:\\vscode\\projects\\stock-market-trend-analysis\\.venv\\lib\\site-packages (1.17.0)\n",
      "Requirement already satisfied: scikit-learn in d:\\vscode\\projects\\stock-market-trend-analysis\\.venv\\lib\\site-packages (1.8.0)\n",
      "Requirement already satisfied: requests>=2.31 in d:\\vscode\\projects\\stock-market-trend-analysis\\.venv\\lib\\site-packages (from yfinance) (2.32.5)\n",
      "Requirement already satisfied: multitasking>=0.0.7 in d:\\vscode\\projects\\stock-market-trend-analysis\\.venv\\lib\\site-packages (from yfinance) (0.0.12)\n",
      "Requirement already satisfied: platformdirs>=2.0.0 in d:\\vscode\\projects\\stock-market-trend-analysis\\.venv\\lib\\site-packages (from yfinance) (4.5.1)\n",
      "Requirement already satisfied: pytz>=2022.5 in d:\\vscode\\projects\\stock-market-trend-analysis\\.venv\\lib\\site-packages (from yfinance) (2025.2)\n",
      "Requirement already satisfied: frozendict>=2.3.4 in d:\\vscode\\projects\\stock-market-trend-analysis\\.venv\\lib\\site-packages (from yfinance) (2.4.7)\n",
      "Requirement already satisfied: peewee>=3.16.2 in d:\\vscode\\projects\\stock-market-trend-analysis\\.venv\\lib\\site-packages (from yfinance) (3.19.0)\n",
      "Requirement already satisfied: beautifulsoup4>=4.11.1 in d:\\vscode\\projects\\stock-market-trend-analysis\\.venv\\lib\\site-packages (from yfinance) (4.14.3)\n",
      "Requirement already satisfied: curl_cffi<0.14,>=0.7 in d:\\vscode\\projects\\stock-market-trend-analysis\\.venv\\lib\\site-packages (from yfinance) (0.13.0)\n",
      "Requirement already satisfied: protobuf>=3.19.0 in d:\\vscode\\projects\\stock-market-trend-analysis\\.venv\\lib\\site-packages (from yfinance) (6.33.4)\n",
      "Requirement already satisfied: websockets>=13.0 in d:\\vscode\\projects\\stock-market-trend-analysis\\.venv\\lib\\site-packages (from yfinance) (16.0)\n",
      "Requirement already satisfied: cffi>=1.12.0 in d:\\vscode\\projects\\stock-market-trend-analysis\\.venv\\lib\\site-packages (from curl_cffi<0.14,>=0.7->yfinance) (2.0.0)\n",
      "Requirement already satisfied: certifi>=2024.2.2 in d:\\vscode\\projects\\stock-market-trend-analysis\\.venv\\lib\\site-packages (from curl_cffi<0.14,>=0.7->yfinance) (2026.1.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in d:\\vscode\\projects\\stock-market-trend-analysis\\.venv\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: tzdata>=2022.7 in d:\\vscode\\projects\\stock-market-trend-analysis\\.venv\\lib\\site-packages (from pandas) (2025.3)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in d:\\vscode\\projects\\stock-market-trend-analysis\\.venv\\lib\\site-packages (from matplotlib) (1.3.3)\n",
      "Requirement already satisfied: cycler>=0.10 in d:\\vscode\\projects\\stock-market-trend-analysis\\.venv\\lib\\site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in d:\\vscode\\projects\\stock-market-trend-analysis\\.venv\\lib\\site-packages (from matplotlib) (4.61.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in d:\\vscode\\projects\\stock-market-trend-analysis\\.venv\\lib\\site-packages (from matplotlib) (1.4.9)\n",
      "Requirement already satisfied: packaging>=20.0 in d:\\vscode\\projects\\stock-market-trend-analysis\\.venv\\lib\\site-packages (from matplotlib) (25.0)\n",
      "Requirement already satisfied: pillow>=8 in d:\\vscode\\projects\\stock-market-trend-analysis\\.venv\\lib\\site-packages (from matplotlib) (12.1.0)\n",
      "Requirement already satisfied: pyparsing>=3 in d:\\vscode\\projects\\stock-market-trend-analysis\\.venv\\lib\\site-packages (from matplotlib) (3.3.1)\n",
      "Requirement already satisfied: click in d:\\vscode\\projects\\stock-market-trend-analysis\\.venv\\lib\\site-packages (from nltk) (8.3.1)\n",
      "Requirement already satisfied: joblib in d:\\vscode\\projects\\stock-market-trend-analysis\\.venv\\lib\\site-packages (from nltk) (1.5.3)\n",
      "Requirement already satisfied: regex>=2021.8.3 in d:\\vscode\\projects\\stock-market-trend-analysis\\.venv\\lib\\site-packages (from nltk) (2026.1.15)\n",
      "Requirement already satisfied: tqdm in d:\\vscode\\projects\\stock-market-trend-analysis\\.venv\\lib\\site-packages (from nltk) (4.67.1)\n",
      "Requirement already satisfied: threadpoolctl>=3.2.0 in d:\\vscode\\projects\\stock-market-trend-analysis\\.venv\\lib\\site-packages (from scikit-learn) (3.6.0)\n",
      "Requirement already satisfied: soupsieve>=1.6.1 in d:\\vscode\\projects\\stock-market-trend-analysis\\.venv\\lib\\site-packages (from beautifulsoup4>=4.11.1->yfinance) (2.8.1)\n",
      "Requirement already satisfied: typing-extensions>=4.0.0 in d:\\vscode\\projects\\stock-market-trend-analysis\\.venv\\lib\\site-packages (from beautifulsoup4>=4.11.1->yfinance) (4.15.0)\n",
      "Requirement already satisfied: pycparser in d:\\vscode\\projects\\stock-market-trend-analysis\\.venv\\lib\\site-packages (from cffi>=1.12.0->curl_cffi<0.14,>=0.7->yfinance) (2.23)\n",
      "Requirement already satisfied: six>=1.5 in d:\\vscode\\projects\\stock-market-trend-analysis\\.venv\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in d:\\vscode\\projects\\stock-market-trend-analysis\\.venv\\lib\\site-packages (from requests>=2.31->yfinance) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in d:\\vscode\\projects\\stock-market-trend-analysis\\.venv\\lib\\site-packages (from requests>=2.31->yfinance) (3.11)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in d:\\vscode\\projects\\stock-market-trend-analysis\\.venv\\lib\\site-packages (from requests>=2.31->yfinance) (2.6.3)\n",
      "Requirement already satisfied: colorama in d:\\vscode\\projects\\stock-market-trend-analysis\\.venv\\lib\\site-packages (from click->nltk) (0.4.6)\n"
     ]
    }
   ],
   "source": [
    "!pip install numpy yfinance pandas matplotlib xgboost nltk --upgrade scipy scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d5cd936b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "import time\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.graph_objects as go\n",
    "import yfinance as yf\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import joblib\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.preprocessing import StandardScaler, RobustScaler\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import silhouette_score\n",
    "from scipy.spatial.distance import euclidean\n",
    "from scipy.spatial.distance import cdist\n",
    "from sklearn.metrics import accuracy_score\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f25841fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initiating resilient download for 50 tickers...\n",
      "Downloading batch: ['NVDA', 'AAPL', 'GOOG', 'MSFT', 'AMZN', 'META', 'TSLA', 'AVGO', '2222.SR', 'TSM', 'BRK-B', 'LLY', 'WMT', 'JPM', 'TCEHY']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  15 of 15 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading batch: ['V', 'ORCL', 'MA', '005930.KS', 'XOM', 'JNJ', 'PLTR', 'BAC', 'ASML', 'ABBV', 'NFLX', '601288.SS', 'COST', 'MC.PA', 'BABA']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  15 of 15 completed\n",
      "[******                13%                       ]  2 of 15 completed"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading batch: ['1398.HK', 'AMD', 'HD', '601939.SS', 'ROG.SW', 'PG', 'GE', 'MU', 'CSCO', 'KO', 'WFC', 'CVX', 'UNH', 'MS', 'SAP']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  15 of 15 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading batch: ['TM', 'AZN', 'IBM', 'CAT', '000660.KS']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  5 of 5 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All tickers downloaded successfully.\n",
      "✓ Data ingestion complete. File saved: d:\\VSCode\\Projects\\Stock-Market-Trend-Analysis\\Data\\market_data_raw.csv\n",
      "✓ Successfully collected 50 tickers\n"
     ]
    }
   ],
   "source": [
    "TOP_50_TICKERS = [\n",
    "    \"NVDA\", \"AAPL\", \"GOOG\", \"MSFT\", \"AMZN\", \"META\", \"TSLA\", \"AVGO\", \"2222.SR\", \"TSM\",\n",
    "    \"BRK-B\", \"LLY\", \"WMT\", \"JPM\", \"TCEHY\", \"V\", \"ORCL\", \"MA\", \"005930.KS\", \"XOM\",\n",
    "    \"JNJ\", \"PLTR\", \"BAC\", \"ASML\", \"ABBV\", \"NFLX\", \"601288.SS\", \"COST\", \"MC.PA\", \"BABA\",\n",
    "    \"1398.HK\", \"AMD\", \"HD\", \"601939.SS\", \"ROG.SW\", \"PG\", \"GE\", \"MU\", \"CSCO\", \"KO\",\n",
    "    \"WFC\", \"CVX\", \"UNH\", \"MS\", \"SAP\", \"TM\", \"AZN\", \"IBM\", \"CAT\", \"000660.KS\"\n",
    "]\n",
    "\n",
    "current_dir = Path.cwd()\n",
    "project_root = current_dir if current_dir.name != 'Notebooks' else current_dir.parent\n",
    "raw_data_path = project_root / \"Data\" \n",
    "raw_data_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "def fetch_tickers_in_batches(tickers, batch_size=10, period=\"6mo\"):\n",
    "    all_data = []\n",
    "    for i in range(0, len(tickers), batch_size):\n",
    "        batch = tickers[i:i + batch_size]\n",
    "        print(f\"Downloading batch: {batch}\")\n",
    "        try:\n",
    "            data = yf.download(batch, period=period, group_by='ticker', auto_adjust=True, threads=True)\n",
    "            if not data.empty:\n",
    "                all_data.append(data)\n",
    "        except Exception as e:\n",
    "            print(f\"Batch download error: {e}\")\n",
    "        time.sleep(1)\n",
    "    return pd.concat(all_data, axis=1) if all_data else pd.DataFrame()\n",
    "\n",
    "def robust_downloader(tickers, period=\"6mo\", max_retries=3):\n",
    "    print(f\"Initiating resilient download for {len(tickers)} tickers...\")\n",
    "    df = fetch_tickers_in_batches(tickers, batch_size=15, period=period)\n",
    "    \n",
    "    for attempt in range(max_retries):\n",
    "        existing_tickers = df.columns.get_level_values(0).unique().tolist()\n",
    "        failed_tickers = [t for t in tickers if t not in existing_tickers]\n",
    "        \n",
    "        if not failed_tickers:\n",
    "            print(\"All tickers downloaded successfully.\")\n",
    "            break\n",
    "            \n",
    "        wait_time = (attempt + 1) * 5\n",
    "        print(f\"Attempt {attempt + 1}/{max_retries}: {len(failed_tickers)} failures. Retrying in {wait_time}s...\")\n",
    "        time.sleep(wait_time)\n",
    "        \n",
    "        for ticker in failed_tickers:\n",
    "            try:\n",
    "                retry_data = yf.download(ticker, period=period, auto_adjust=True, progress=False)\n",
    "                if not retry_data.empty and len(retry_data) > 20:\n",
    "                    if not isinstance(retry_data.columns, pd.MultiIndex):\n",
    "                        retry_data.columns = pd.MultiIndex.from_product([[ticker], retry_data.columns])\n",
    "                    df = pd.concat([df, retry_data], axis=1)\n",
    "                    print(f\"✓ Successfully retrieved {ticker}\")\n",
    "            except Exception as e:\n",
    "                print(f\"✗ Failed for {ticker}: {str(e)[:50]}\")\n",
    "\n",
    "    df = df.sort_index().interpolate(method='time').ffill().bfill()\n",
    "    \n",
    "    missing_final = [t for t in tickers if t not in df.columns.get_level_values(0).unique()]\n",
    "    if missing_final:\n",
    "        print(f\"⚠ CRITICAL: Still missing {len(missing_final)} tickers: {missing_final}\")\n",
    "    \n",
    "    file_path = raw_data_path / \"market_data_raw.csv\"\n",
    "    df.to_csv(file_path)\n",
    "    print(f\"✓ Data ingestion complete. File saved: {file_path}\")\n",
    "    print(f\"✓ Successfully collected {df.columns.get_level_values(0).nunique()} tickers\")\n",
    "    return df\n",
    "\n",
    "raw_df = robust_downloader(TOP_50_TICKERS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b47c2594",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading raw data and calculating features...\n",
      "✓ Processed AMZN: 141 days\n",
      "✓ Processed GOOG: 141 days\n",
      "✓ Processed TSLA: 141 days\n",
      "✓ Processed MSFT: 141 days\n",
      "✓ Processed TCEHY: 141 days\n",
      "✓ Processed META: 141 days\n",
      "✓ Processed NVDA: 141 days\n",
      "✓ Processed AVGO: 141 days\n",
      "✓ Processed BRK-B: 141 days\n",
      "✓ Processed LLY: 141 days\n",
      "✓ Processed 2222.SR: 141 days\n",
      "✓ Processed AAPL: 141 days\n",
      "✓ Processed WMT: 141 days\n",
      "✓ Processed JPM: 141 days\n",
      "✓ Processed TSM: 141 days\n",
      "✓ Processed ORCL: 141 days\n",
      "✓ Processed 601288.SS: 141 days\n",
      "✓ Processed BABA: 141 days\n",
      "✓ Processed NFLX: 141 days\n",
      "✓ Processed V: 141 days\n",
      "✓ Processed MA: 141 days\n",
      "✓ Processed 005930.KS: 141 days\n",
      "✓ Processed PLTR: 141 days\n",
      "✓ Processed ABBV: 141 days\n",
      "✓ Processed MC.PA: 141 days\n",
      "✓ Processed BAC: 141 days\n",
      "✓ Processed ASML: 141 days\n",
      "✓ Processed XOM: 141 days\n",
      "✓ Processed COST: 141 days\n",
      "✓ Processed JNJ: 141 days\n",
      "✓ Processed 1398.HK: 141 days\n",
      "✓ Processed 601939.SS: 141 days\n",
      "✓ Processed HD: 141 days\n",
      "✓ Processed CSCO: 141 days\n",
      "✓ Processed AMD: 141 days\n",
      "✓ Processed MU: 141 days\n",
      "✓ Processed ROG.SW: 141 days\n",
      "✓ Processed UNH: 141 days\n",
      "✓ Processed SAP: 141 days\n",
      "✓ Processed WFC: 141 days\n",
      "✓ Processed MS: 141 days\n",
      "✓ Processed CVX: 141 days\n",
      "✓ Processed KO: 141 days\n",
      "✓ Processed PG: 141 days\n",
      "✓ Processed GE: 141 days\n",
      "✓ Processed AZN: 141 days\n",
      "✓ Processed TM: 141 days\n",
      "✓ Processed 000660.KS: 141 days\n",
      "✓ Processed CAT: 141 days\n",
      "✓ Processed IBM: 141 days\n",
      "\n",
      "✓ Total: 7050 rows across 50 tickers\n",
      "✓ File saved: d:\\VSCode\\Projects\\Stock-Market-Trend-Analysis\\Data\\market_data_features.csv\n"
     ]
    }
   ],
   "source": [
    "current_dir = Path.cwd()\n",
    "project_root = current_dir if current_dir.name != 'Notebooks' else current_dir.parent\n",
    "raw_file = project_root / \"Data\" / \"market_data_raw.csv\"\n",
    "proc_dir = project_root / \"Data\" \n",
    "proc_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "def calculate_indicators(df):\n",
    "    \"\"\"Calculates technical indicators\"\"\"\n",
    "    df = df.copy()  # Avoid SettingWithCopyWarning\n",
    "    \n",
    "    # RSI_14\n",
    "    delta = df['Close'].diff()\n",
    "    gain = (delta.where(delta > 0, 0)).rolling(window=14).mean()\n",
    "    loss = (-delta.where(delta < 0, 0)).rolling(window=14).mean()\n",
    "    rs = gain / loss\n",
    "    df['RSI_14'] = 100 - (100 / (1 + rs))\n",
    "\n",
    "    # SMA Ratio 5/20\n",
    "    df['SMA_5'] = df['Close'].rolling(window=5).mean()\n",
    "    df['SMA_20'] = df['Close'].rolling(window=20).mean()\n",
    "    df['SMA_Ratio_5_20'] = df['SMA_5'] / df['SMA_20']\n",
    "\n",
    "    # MACD Histogram\n",
    "    ema12 = df['Close'].ewm(span=12, adjust=False).mean()\n",
    "    ema26 = df['Close'].ewm(span=26, adjust=False).mean()\n",
    "    df['MACD'] = ema12 - ema26\n",
    "    df['Signal'] = df['MACD'].ewm(span=9, adjust=False).mean()\n",
    "    df['MACD_Histogram'] = df['MACD'] - df['Signal']\n",
    "\n",
    "    # Bollinger Bands Position\n",
    "    std = df['Close'].rolling(window=20).std()\n",
    "    df['BB_Upper'] = df['SMA_20'] + (std * 2)\n",
    "    df['BB_Lower'] = df['SMA_20'] - (std * 2)\n",
    "    df['BB_Position'] = (df['Close'] - df['BB_Lower']) / (df['BB_Upper'] - df['BB_Lower'])\n",
    "\n",
    "    # Volume Ratio\n",
    "    df['Vol_SMA_20'] = df['Volume'].rolling(window=20).mean()\n",
    "    df['Volume_Ratio'] = df['Volume'] / df['Vol_SMA_20']\n",
    "\n",
    "    return df.dropna()\n",
    "\n",
    "print(\"Loading raw data and calculating features...\")\n",
    "df_raw = pd.read_csv(raw_file, header=[0, 1], index_col=0, parse_dates=True)\n",
    "tickers = df_raw.columns.get_level_values(0).unique()\n",
    "\n",
    "all_processed = []\n",
    "for ticker in tickers:\n",
    "    try:\n",
    "        stock_data = df_raw[ticker].copy()\n",
    "        if stock_data.empty or len(stock_data) < 50:\n",
    "            print(f\"⚠ Skipping {ticker}: Insufficient data ({len(stock_data)} days)\")\n",
    "            continue \n",
    "\n",
    "        processed_stock = calculate_indicators(stock_data)\n",
    "        processed_stock['Ticker'] = ticker  # No more SettingWithCopyWarning\n",
    "        all_processed.append(processed_stock)\n",
    "        print(f\"✓ Processed {ticker}: {len(processed_stock)} days\")\n",
    "    except Exception as e:\n",
    "        print(f\"✗ Error processing {ticker}: {str(e)[:50]}\")\n",
    "\n",
    "final_df = pd.concat(all_processed)\n",
    "final_df.to_csv(proc_dir / \"market_data_features.csv\")\n",
    "print(f\"\\n✓ Total: {len(final_df)} rows across {final_df['Ticker'].nunique()} tickers\")\n",
    "print(f\"✓ File saved: {proc_dir / 'market_data_features.csv'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dd6d9ed7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected 705 anomalies across all tickers.\n"
     ]
    }
   ],
   "source": [
    "anomaly_df = pd.read_csv(proc_dir / \"market_data_features.csv\")\n",
    "model_root = project_root / \"Models\"\n",
    "model_root.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "features = [\n",
    "    'RSI_14',\n",
    "    'SMA_Ratio_5_20',\n",
    "    'MACD_Histogram',\n",
    "    'BB_Position',\n",
    "    'Volume_Ratio'\n",
    "]\n",
    "\n",
    "clean_anomaly_df = anomaly_df.dropna(subset=features).copy()\n",
    "\n",
    "iso_model = IsolationForest(n_estimators=100, max_samples='auto', contamination=0.10, random_state=42, max_features=len(features), n_jobs=-1)\n",
    "\n",
    "clean_anomaly_df['Anomaly_Flag'] = iso_model.fit_predict(clean_anomaly_df[features])\n",
    "clean_anomaly_df['Is_Anomaly'] = clean_anomaly_df['Anomaly_Flag'].apply(lambda x: 1 if x == -1 else 0)\n",
    "\n",
    "joblib.dump(iso_model, model_root / \"isolation_forest_model.pkl\")\n",
    "clean_anomaly_df.to_csv(proc_dir / \"market_data_anomalies.csv\", index=False)\n",
    "\n",
    "print(f\"Detected {clean_anomaly_df['Is_Anomaly'].sum()} anomalies across all tickers.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bedef5a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Ticker  Cluster  Distance     RSI_14  SMA_Ratio_5_20  MACD_Histogram  \\\n",
      "9    AMZN        2  0.609341  59.823787        1.015117       -0.159489   \n",
      "20     GE        2  0.807588  60.864803        1.009872       -0.832476   \n",
      "45    UNH        2  0.819458  58.988426        1.000641       -0.506044   \n",
      "\n",
      "    BB_Position  Volume_Ratio  \n",
      "9      0.550899      1.208331  \n",
      "20     0.546844      1.075569  \n",
      "45     0.571502      1.175841  \n"
     ]
    }
   ],
   "source": [
    "clustering_df = pd.read_csv(proc_dir / \"market_data_anomalies.csv\")\n",
    "clean_df = clustering_df.dropna(subset=features).copy()\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(clean_df[features])\n",
    "\n",
    "optimal_k = 5\n",
    "kmeans = KMeans(n_clusters=optimal_k, random_state=42, n_init=10)\n",
    "clean_df['Cluster'] = kmeans.fit_predict(X_scaled)\n",
    "\n",
    "model_root = project_root / \"Models\"\n",
    "model_root.mkdir(parents=True, exist_ok=True)\n",
    "joblib.dump(kmeans, model_root / \"kmeans_model.pkl\")\n",
    "joblib.dump(scaler, model_root / \"scaler.pkl\")\n",
    "clean_df.to_csv(proc_dir / \"market_data_clusters.csv\", index=False)\n",
    "\n",
    "def find_similar_tickers(query_features_dict, df, kmeans_model, scaler_model, top_n=5):\n",
    "    query_df = pd.DataFrame([query_features_dict])\n",
    "    query_scaled = scaler_model.transform(query_df[features])\n",
    "    \n",
    "    query_cluster = kmeans_model.predict(query_scaled)[0]\n",
    "    \n",
    "    latest_states = df.sort_values('Date').groupby('Ticker').last().reset_index()\n",
    "    cluster_peers = latest_states[latest_states['Cluster'] == query_cluster].copy()\n",
    "    \n",
    "    if cluster_peers.empty:\n",
    "        return pd.DataFrame()\n",
    "        \n",
    "    peer_features_scaled = scaler_model.transform(cluster_peers[features])\n",
    "    distances = cdist(query_scaled, peer_features_scaled, metric='euclidean')[0]\n",
    "    \n",
    "    cluster_peers['Distance'] = distances\n",
    "    return cluster_peers.nsmallest(top_n, 'Distance')[['Ticker', 'Cluster', 'Distance'] + features]\n",
    "\n",
    "query_features = {\n",
    "    'RSI_14': 65.5, \n",
    "    'SMA_Ratio_5_20': 1.02, \n",
    "    'MACD_Histogram': 0.5,\n",
    "    'BB_Position': 0.7, \n",
    "    'Volume_Ratio': 1.3\n",
    "}\n",
    "\n",
    "similar = find_similar_tickers(query_features, clean_df, kmeans, scaler, top_n=3)\n",
    "print(similar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "edd4ce6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directional Accuracy: 52.48%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['d:\\\\VSCode\\\\Projects\\\\Stock-Market-Trend-Analysis\\\\Models\\\\trend_model.pkl']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(proc_dir / \"market_data_clusters.csv\")\n",
    "df['Target'] = (df.groupby('Ticker')['Close'].shift(-1) > df['Close']).astype(int)\n",
    "features = [\n",
    "    'RSI_14', \n",
    "    'MACD_Histogram',\n",
    "    'BB_Position', \n",
    "    'SMA_Ratio_5_20',\n",
    "    'Volume_Ratio', \n",
    "    'Is_Anomaly', \n",
    "    'Cluster'\n",
    "]\n",
    "clean_df = df.dropna(subset=['Target'] + features).copy()\n",
    "split_idx = int(len(clean_df) * 0.8)\n",
    "train_df = clean_df.iloc[:split_idx]\n",
    "test_df = clean_df.iloc[split_idx:]\n",
    "X_train, y_train = train_df[features], train_df['Target']\n",
    "X_test, y_test = test_df[features], test_df['Target']\n",
    "\n",
    "xgb_model = xgb.XGBClassifier(n_estimators=500,learning_rate=0.05,max_depth=5,random_state=42,eval_metric='logloss')\n",
    "xgb_model.fit(X_train, y_train,eval_set=[(X_test, y_test)],verbose=False)\n",
    "\n",
    "y_pred = xgb_model.predict(X_test)\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "print(f\"Directional Accuracy: {acc:.2%}\")\n",
    "\n",
    "joblib.dump(xgb_model, model_root / \"trend_model.pkl\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
